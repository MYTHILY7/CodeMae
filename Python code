import os
import logging
from bs4 import BeautifulSoup

# Logging configuration
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

def extract_product_from_closing_disclosure(soup):
    """
    Extract product value from the 'Closing Disclosure' page only.
    """
    for page_div in soup.find_all("div", class_="Page"):
        page_number = page_div.get("data-page-number", "Unknown")
        title_tag = page_div.find("h1", class_="Title")
        if title_tag and title_tag.get_text(strip=True).lower() == "closing disclosure":
            # Method 1: Table structure
            for row in page_div.find_all("tr"):
                cells = row.find_all("td")
                if len(cells) >= 2:
                    label = cells[0].get_text(strip=True).lower()
                    value = cells[1].get_text(strip=True)
                    if "product" == label and value:
                        logging.info(f'üîç Product "{value.strip()}" extracted from Closing Disclosure on page {page_number}')
                        logging.info(f'üîé Product block (table row): {row}')
                        return value.strip().lower(), page_number

            # Method 2: Paragraph block style
            paragraphs = page_div.find_all("p")
            for i, p in enumerate(paragraphs):
                if p.get_text(strip=True).lower() == "product":
                    for j in range(i+1, min(i+5, len(paragraphs))):
                        val = paragraphs[j].get_text(strip=True)
                        if val and val.lower() not in ["loan term", "loan type", "purpose"]:
                            logging.info(f'üîç Product "{val.strip()}" extracted from Closing Disclosure on page {page_number}')
                            logging.info(f'üîé Product block (paragraph): {paragraphs[j].parent}')
                            return val.strip().lower(), page_number
    return None, None

# Example usage
def process_html_file(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            soup = BeautifulSoup(f, 'html.parser')
        product, page = extract_product_from_closing_disclosure(soup)
        if product:
            logging.info(f'‚úÖ Product found: "{product}" on page {page} in file: {os.path.basename(file_path)}')
        else:
            logging.error(f'‚ùå Product not found in Closing Disclosure of file: {os.path.basename(file_path)}')
    except Exception as e:
        logging.error(f'‚ùå Error processing {os.path.basename(file_path)}: {str(e)}')

# Driver
if __name__ == "__main__":
    html_files = ['pdf1.html', 'pdf10.html', 'pdf1454.html']
    for file in html_files:
        process_html_file(file)
