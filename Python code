import os
import logging
from bs4 import BeautifulSoup

# Logging configuration
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')


def extract_product_from_closing_disclosure(soup):
    """
    Extract product value from the 'Closing Disclosure' page.
    """
    for page_div in soup.find_all("div", class_="Page"):
        page_number = page_div.get("data-page-number", "Unknown")
        title_tag = page_div.find("h1", class_="Title")
        if title_tag and title_tag.get_text(strip=True).lower() == "closing disclosure":
            # Table format
            for row in page_div.find_all("tr"):
                cells = row.find_all("td")
                if len(cells) >= 2:
                    label = cells[0].get_text(strip=True).lower()
                    value = cells[1].get_text(strip=True)
                    if "product" == label and value:
                        logging.info(f'üîç Product "{value.strip()}" extracted from Closing Disclosure on page {page_number}')
                        logging.info(f'üîé Product block (table row): {row}')
                        return value.strip().lower(), row, page_number

            # Paragraph-based format
            paragraphs = page_div.find_all("p")
            for i, p in enumerate(paragraphs):
                if p.get_text(strip=True).lower() == "product":
                    for j in range(i+1, min(i+5, len(paragraphs))):
                        val = paragraphs[j].get_text(strip=True)
                        if val and val.lower() not in ["loan term", "loan type", "purpose"]:
                            logging.info(f'üîç Product "{val.strip()}" extracted from Closing Disclosure on page {page_number}')
                            logging.info(f'üîé Product block (paragraph): {paragraphs[j].parent}')
                            return val.strip().lower(), paragraphs[j].parent, page_number
    return None, None, None


def extract_correct_note_div(soup):
    """
    Extract the correct NOTE section based on the presence of legal clause like "BORROWER'S PROMISE TO PAY".
    """
    candidates = []
    for page_div in soup.find_all("div", class_="Page"):
        page_number = page_div.get("data-page-number", "Unknown")
        if any(h.get_text(strip=True).lower() == "note" for h in page_div.find_all(['h1', 'h2'])):
            full_text = page_div.get_text(separator=" ", strip=True).lower()
            if "borrower's promise to pay" in full_text:
                logging.info(f'üìå Selected NOTE page with clause on page {page_number}')
                return page_div, page_number
            candidates.append((page_div, page_number))

    # Fallback if no NOTE clause found
    if candidates:
        fallback_page, fallback_number = candidates[0]
        logging.warning(f"‚ö†Ô∏è Falling back to first NOTE page on page {fallback_number}")
        return fallback_page, fallback_number

    return None, None


def extract_footer_text(note_div):
    """
    Extract footer or end block text from the NOTE page.
    """
    if not note_div:
        return ""

    footer_texts = []
    for tag in note_div.find_all(['footer', 'p', 'span', 'div']):
        text = tag.get_text(separator=" ", strip=True)
        if text:
            footer_texts.append(text)

    joined_text = " ".join(footer_texts)
    logging.info(f'üßæ NOTE footer block (first 400 chars): {joined_text[:400]}...')
    return joined_text.lower()


def process_html_file(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            soup = BeautifulSoup(f, 'html.parser')

        product, product_block, closing_page = extract_product_from_closing_disclosure(soup)
        if not product:
            logging.error(f'‚ùå Product not found in Closing Disclosure in: {os.path.basename(file_path)}')
            return

        note_div, note_page = extract_correct_note_div(soup)
        if not note_div:
            logging.error(f'‚ùå Correct NOTE section not found in: {os.path.basename(file_path)}')
            return

        footer_text = extract_footer_text(note_div)
        if not footer_text:
            logging.error(f'‚ùå Footer text missing in NOTE on page {note_page}')
            return

        if product in footer_text:
            logging.info(f'‚úÖ PASS: Product "{product}" from page {closing_page} found in NOTE on page {note_page}')
        else:
            logging.error(f'‚ùå FAIL: Product "{product}" from page {closing_page} NOT found in NOTE footer on page {note_page}')

        # Print both blocks
        logging.info(f'\nüìÑ Product block (page {closing_page}):\n{product_block}\n')
        logging.info(f'\nüìÑ NOTE block (page {note_page}):\n{note_div}\n')

    except Exception as e:
        logging.error(f'‚ùå Error processing file {os.path.basename(file_path)}: {str(e)}')


# Run for all files
if __name__ == "__main__":
    html_files = ['pdf1.html', 'pdf10.html', 'pdf1454.html', 'pdf2.html', 'pdf4.html']
    for file in html_files:
        process_html_file(file)
