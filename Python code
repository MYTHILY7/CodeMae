import os
import logging
from bs4 import BeautifulSoup

# Logging configuration
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

def extract_product_from_closing_disclosure(soup):
    """
    Extract product value from the 'Closing Disclosure' page only.
    """
    for page_div in soup.find_all("div", class_="Page"):
        page_number = page_div.get("data-page-number", "Unknown")
        title_tag = page_div.find("h1", class_="Title")
        if title_tag and title_tag.get_text(strip=True).lower() == "closing disclosure":
            for row in page_div.find_all("tr"):
                cells = row.find_all("td")
                if len(cells) >= 2:
                    label = cells[0].get_text(strip=True).lower()
                    value = cells[1].get_text(strip=True)
                    if "product" == label and value:
                        logging.info(f'üîç Product "{value.strip()}" extracted from Closing Disclosure on page {page_number}')
                        logging.info(f'üîé Product block (table row): {row}')
                        return value.strip().lower(), page_number

            # Paragraph-based format
            paragraphs = page_div.find_all("p")
            for i, p in enumerate(paragraphs):
                if p.get_text(strip=True).lower() == "product":
                    for j in range(i+1, min(i+5, len(paragraphs))):
                        val = paragraphs[j].get_text(strip=True)
                        if val and val.lower() not in ["loan term", "loan type", "purpose"]:
                            logging.info(f'üîç Product "{val.strip()}" extracted from Closing Disclosure on page {page_number}')
                            logging.info(f'üîé Product block (paragraph): {paragraphs[j].parent}')
                            return val.strip().lower(), page_number
    return None, None

def extract_note_div(soup):
    """
    Find the <div class='Page'> that contains the 'NOTE' heading.
    """
    for page_div in soup.find_all("div", class_="Page"):
        page_number = page_div.get("data-page-number", "Unknown")
        for heading in page_div.find_all(['h1', 'h2', 'h3']):
            if heading.get_text(strip=True).lower() == "note":
                logging.info(f'üìÑ Found NOTE section on page {page_number}')
                return page_div, page_number
    return None, None

def extract_footer_text(note_div):
    """
    Get all text from the footer or last sections in the NOTE div.
    """
    if not note_div:
        return ""
    elements = note_div.find_all(['footer', 'p', 'span', 'div'])
    combined = " ".join(el.get_text(separator=" ", strip=True) for el in elements)
    logging.info(f'üßæ NOTE footer block: {combined[:400]}...')  # Print first 400 characters
    return combined.lower()

def process_html_file(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            soup = BeautifulSoup(f, 'html.parser')

        product, closing_page = extract_product_from_closing_disclosure(soup)
        if not product:
            logging.error(f'FAIL: Product type not found in Closing Disclosure of file: {os.path.basename(file_path)}')
            return

        note_div, note_page = extract_note_div(soup)
        if not note_div:
            logging.error(f'FAIL: NOTE section not found in file: {os.path.basename(file_path)}')
            return

        footer_text = extract_footer_text(note_div)
        if not footer_text:
            logging.error(f'FAIL: Footer not found in NOTE section of file: {os.path.basename(file_path)}')
            return

        if product in footer_text:
            logging.info(f'‚úÖ PASS: Product "{product}" from page {closing_page} matched in NOTE footer on page {note_page} in file: {os.path.basename(file_path)}')
        else:
            logging.error(f'‚ùå FAIL: Product "{product}" from page {closing_page} NOT found in NOTE footer on page {note_page} of file: {os.path.basename(file_path)}')

    except Exception as e:
        logging.error(f'‚ùå Error processing {os.path.basename(file_path)}: {str(e)}')

# Run for multiple HTML files
if __name__ == "__main__":
    html_files = ['pdf1.html', 'pdf10.html', 'pdf1454.html','pdf2.html','pdf4.html']
    for file in html_files:
        process_html_file(file)
